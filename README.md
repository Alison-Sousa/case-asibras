# ğŸ“Š RepositÃ³rio de AnÃ¡lises e Modelagem de Dados

Este projeto consolida dois pipelines completos de ciÃªncia de dados, demonstrando metodologias de classificaÃ§Ã£o e previsÃ£o de sÃ©ries temporais. Cada anÃ¡lise Ã© autocontida e inclui desde o prÃ©-processamento dos dados atÃ© a interpretaÃ§Ã£o dos resultados do modelo.

## ğŸ“‚ Estrutura do Projeto

A organizaÃ§Ã£o deste repositÃ³rio foi pensada para separar os dados, o cÃ³digo-fonte e os relatÃ³rios de anÃ¡lise.

â”œâ”€â”€ ğŸ“„ README.md # (Este arquivo)

â”œâ”€â”€ ğŸ“¦ data/

â”‚   â”œâ”€â”€ âœˆï¸ AirPassengers.csv # Dados brutos da sÃ©rie temporal

â”‚   â””â”€â”€ ğŸš¶â€â™‚ï¸ Churn.csv  # Dados brutos de churn de clientes

â”‚

â”œâ”€â”€ ğŸ“‘ reports/

â”‚   â”œâ”€â”€ âœˆï¸ AirPassengers_Report.pdf # (RelatÃ³rio tÃ©cnico em LaTeX/PDF da anÃ¡lise 2)

â”‚   â””â”€â”€ ğŸš¶â€â™‚ï¸ Churn_Report.pdf # (RelatÃ³rio tÃ©cnico em LaTeX/PDF da anÃ¡lise 1)

â”‚

â”œâ”€â”€ ğŸ’» src/ case.ipynb

â”‚   â”œâ”€â”€ âœˆï¸ 02_Pipeline_Series_Temporais.ipynb # Notebook com o cÃ³digo e saÃ­das da AnÃ¡lise 2

â”‚   â””â”€â”€ ğŸš¶â€â™‚ï¸ 01_Pipeline_Churn.ipynb # Notebook com o cÃ³digo e saÃ­das da AnÃ¡lise 1

â”œâ”€â”€ ğŸ”§ requirements.txt  # Lista de bibliotecas


* `data/`: ContÃ©m os conjuntos de dados brutos em formato `.csv` que servem de entrada para os pipelines.
* `reports/`: ContÃ©m os relatÃ³rios tÃ©cnicos formais (gerados em LaTeX e compilados em PDF) que detalham e interpretam os resultados encontrados nos *notebooks*.
* `src/`: ContÃ©m os *notebooks* Jupyter (ou scripts Python) com todo o processo de anÃ¡lise, incluindo cÃ³digo, visualizaÃ§Ãµes e saÃ­das de execuÃ§Ã£o.
* `requirements.txt`: Arquivo que especifica as bibliotecas e suas versÃµes para garantir a reprodutibilidade das anÃ¡lises.

---

## 1. ğŸš¶â€â™‚ï¸ AnÃ¡lise de Churn de Clientes (Telco)

Esta anÃ¡lise aborda um problema de **classificaÃ§Ã£o binÃ¡ria** para prever se um cliente irÃ¡ ou nÃ£o cancelar seu contrato (`Churn: Yes/No`).

### ğŸ¯ O Problema
O objetivo Ã© construir um modelo que nÃ£o apenas preveja o *churn*, mas que tambÃ©m nos ajude a entender **quais fatores** mais influenciam essa decisÃ£o. Isso permite que a empresa atue de forma proativa para reter clientes em risco.

### âš™ï¸ Metodologia de ExecuÃ§Ã£o
O pipeline (`src/01_Pipeline_Churn.ipynb`) executa as seguintes etapas:

1.  **PrÃ©-processamento:**
    * A coluna `TotalCharges` Ã© convertida de `object` para `numeric`, e os 11 valores ausentes (de clientes novos) sÃ£o preenchidos com `0`.
    * As variÃ¡veis numÃ©ricas (`tenure`, `MonthlyCharges`, `TotalCharges`) sÃ£o padronizadas (com `StandardScaler`).
    * As variÃ¡veis categÃ³ricas sÃ£o transformadas em colunas binÃ¡rias (com `OneHotEncoder`).
    * Os dados sÃ£o divididos em treino (80%) e teste (20%) de forma **estratificada**, garantindo que a proporÃ§Ã£o de *churn* (26.54%) seja idÃªntica em ambos os conjuntos.

2.  **Modelagem Comparativa:**
    * **RegressÃ£o LogÃ­stica:** Um modelo linear, interpretÃ¡vel por padrÃ£o.
    * **XGBoost:** Um modelo baseado em *gradient boosting*, conhecido por seu alto desempenho.

3.  **Explicabilidade (XAI) com SHAP:**
    * O modelo XGBoost Ã© analisado usando valores SHAP para entender o impacto de cada variÃ¡vel.
    * O cÃ³digo detectou uma incompatibilidade de versÃ£o entre o `xgboost` (v3.1.1) e o `shap` (v0.49.1), que impedia o uso do `TreeExplainer` (devido ao formato do `base_score`).
    * O pipeline ativou com sucesso um mecanismo de *fallback*, utilizando o `PermutationExplainer`, que Ã© agnÃ³stico ao modelo e permitiu o cÃ¡lculo das contribuiÃ§Ãµes de cada *feature*.

### ğŸ“Š Resultados Principais
* **Desempenho:** No conjunto de teste, o modelo de **RegressÃ£o LogÃ­stica (AUC: 0.8421)** apresentou um poder de discriminaÃ§Ã£o ligeiramente superior ao **XGBoost (AUC: 0.8152)**. Em termos de F1-Score para a classe "Churn", a RegressÃ£o LogÃ­stica (0.61) tambÃ©m superou o XGBoost (0.54).
* **ImportÃ¢ncia (SHAP):** A anÃ¡lise de explicabilidade do XGBoost identificou os principais fatores de influÃªncia:
    1.  `tenure`: O fator mais importante. Clientes com baixo tempo de contrato tÃªm uma propensÃ£o muito maior ao *churn*.
    2.  `Contract_Month-to-month`: Ter um contrato "mÃªs a mÃªs" (sem fidelidade) Ã© o segundo maior indicador de risco de *churn*.
    3.  `MonthlyCharges`: Clientes com cobranÃ§as mensais mais altas tendem a cancelar mais.

---

## 2. âœˆï¸ PrevisÃ£o de SÃ©ries Temporais (AirPassengers)

Esta anÃ¡lise aborda um problema de **regressÃ£o para previsÃ£o de sÃ©rie temporal univariada**.

### ğŸ¯ O Problema
O objetivo Ã© prever o nÃºmero de passageiros de companhias aÃ©reas para os prÃ³ximos meses, com base em 144 observaÃ§Ãµes mensais (12 anos, de 1949 a 1960).

### âš™ï¸ Metodologia de ExecuÃ§Ã£o
O pipeline (`src/02_Pipeline_Series_Temporais.ipynb`) segue um fluxo rigoroso para modelagem temporal:

1.  **AnÃ¡lise ExploratÃ³ria (EDA):**
    * A sÃ©rie temporal (Figura `serie_temporal.png`) mostra uma clara **TendÃªncia** de crescimento e uma forte **Sazonalidade** de 12 meses.
    * A variÃ¢ncia da sazonalidade aumenta junto com o nÃ­vel da sÃ©rie, indicando uma natureza **multiplicativa**.
    * A decomposiÃ§Ã£o multiplicativa (Figura `decomposicao.png`) isola com sucesso os trÃªs componentes (TendÃªncia, Sazonalidade e ResÃ­duos).

2.  **Testes de Estacionariedade:**
    * Os testes **ADF (p=0.99)** e **KPSS (p=0.01)** confirmam inequivocamente que a sÃ©rie original nÃ£o Ã© estacionÃ¡ria, necessitando de diferenciaÃ§Ã£o e/ou transformaÃ§Ã£o.

3.  **Modelagem Comparativa:**
    * **SARIMA (SARIMAX):** Modelo estatÃ­stico clÃ¡ssico. Foi aplicada uma transformaÃ§Ã£o de `log` para estabilizar a variÃ¢ncia. Uma busca em grade (grid search) por AIC encontrou a ordem Ã³tima `(1, 0, 0)x(1, 0, 1, 12)`.
    * **Random Forest (com Lags):** Modelo de *machine learning*. Para que o RF "entendesse" o tempo, foram criadas *features* como: lags (1 a 12), mÃ©dias mÃ³veis (janela 12) e o mÃªs do ano.
    * **Naive Sazonal:** Modelo de *baseline* que prevÃª o valor do mesmo mÃªs do ano anterior.

4.  **ValidaÃ§Ã£o (Walk-Forward):**
    * Foi utilizada a metodologia de **validaÃ§Ã£o *walk-forward*** (ou *expanding window*) para os 24 meses do perÃ­odo de teste (1959-1960).
    * Para prever *cada* ponto de teste, os modelos foram **completamente re-treinados** com todos os dados histÃ³ricos disponÃ­veis atÃ© aquele ponto, simulando um ambiente de produÃ§Ã£o real e evitando qualquer vazamento de dados (*data leakage*).

### ğŸ“Š Resultados Principais

* **Desempenho (MÃ©tricas):** O **SARIMA foi o vencedor indiscutÃ­vel**, com um Erro Percentual MÃ©dio (MAPE) de apenas **2.44%**.

    Abaixo estÃ¡ a comparaÃ§Ã£o de desempenho, ordenada do melhor (menor erro) para o pior:

    **ğŸ¥‡ 1. SARIMA (SARIMAX)**
    * **MAE:** 11.15
    * **RMSE:** 15.31
    * **MAPE:** 2.44%

    **ğŸ¥ˆ 2. RandomForest (lags)**
    * MAE: 23.84
    * RMSE: 32.76
    * MAPE: 5.02%

    **ğŸ¥‰ 3. Naive Sazonal (Baseline)**
    * MAE: 47.58
    * RMSE: 49.99
    * MAPE: 10.52%

* **AnÃ¡lise GrÃ¡fica:** O grÃ¡fico de previsÃµes (`forecast_vs_real.png`) mostra que o SARIMA (azul) capturou perfeitamente tanto a tendÃªncia crescente quanto a sazonalidade. O RandomForest (verde) aprendeu a sazonalidade, mas falhou em extrapolar a tendÃªncia (suas previsÃµes ficaram "achatadas").

* **DiagnÃ³stico de ResÃ­duos:** A anÃ¡lise final (`diagnostico_residuos.png`) confirmou a superioridade do SARIMA.
    * **SARIMA:** Os resÃ­duos nÃ£o apresentaram autocorrelaÃ§Ã£o (Teste Ljung-Box p=0.10), comportando-se como **ruÃ­do branco**. Isso indica que o modelo capturou toda a informaÃ§Ã£o previsÃ­vel dos dados.
    * **Random Forest:** Os resÃ­duos mostraram padrÃµes claros de autocorrelaÃ§Ã£o, indicando que o modelo estava **subajustado (*underfit*)** e deixou informaÃ§Ã£o por capturar.

---

## ğŸš€ Como Reproduzir os Resultados

### 1. ğŸ”§ ConfiguraÃ§Ã£o do Ambiente
Clone este repositÃ³rio e instale as dependÃªncias listadas no arquivo `requirements.txt`.

```bash
git clone https://[https://github.com/Alison-Sousa/case-asibras.git]
cd [case-asibras]
pip install -r requirements.txt
2. ğŸ’» ExecuÃ§Ã£o
Abra os notebooks na pasta src/ usando o Jupyter Notebook ou Google Colab.

Para 01_Pipeline_Churn.ipynb, vocÃª precisarÃ¡ fazer o upload do arquivo data/Churn.csv quando o script solicitar.

Para 02_Pipeline_Series_Temporais.ipynb, o pipeline tambÃ©m permite o upload do data/AirPassengers.csv, embora o script tenha um fallback para carregar o dataset padrÃ£o do statsmodels.

3. ğŸ“¦ Bibliotecas Principais (requirements.txt)
pandas
numpy
scikit-learn
xgboost==1.7.6  # VersÃ£o especÃ­fica usada no pipeline de Churn
shap==0.44.1    # VersÃ£o especÃ­fica usada no pipeline de Churn
statsmodels
matplotlib
seaborn